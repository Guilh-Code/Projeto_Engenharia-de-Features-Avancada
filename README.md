# Projeto: Engenharia de Features Avan√ßada para An√°lise do Mercado de IA

<div align="center">
  <img src="https://img.shields.io/badge/Status-Conclu√≠do-brightgreen" alt="Status: Conclu√≠do">
</div>
<br>

## üìú Vis√£o Geral do Projeto

Este projeto representa uma imers√£o profunda na **Engenharia e An√°lise de Dados**, utilizando um dataset sint√©tico sobre vagas no mercado de Intelig√™ncia Artificial. O objetivo principal n√£o foi construir um modelo preditivo de alta performance, mas sim realizar um trabalho minucioso de transforma√ß√£o de dados brutos em uma base anal√≠tica rica e inteligente, pronta para qualquer tipo de an√°lise ou modelagem.

O grande diferencial deste projeto √© a complexidade e a criatividade aplicadas na **Engenharia de Features com SQL**, demonstrando como extrair o m√°ximo de valor e intelig√™ncia de um conjunto de dados antes mesmo da aplica√ß√£o de algoritmos de Machine Learning.

## üéØ O Desafio Central

Partindo de um dataset em formato CSV com informa√ß√µes textuais e semi-estruturadas, o desafio era realizar um ciclo completo de Data Engineering e Data Science, com foco em:
1.  Estruturar os dados em um banco de dados relacional (SQLite).
2.  Realizar uma limpeza profunda e uma an√°lise explorat√≥ria (EDA) para entender a "personalidade" dos dados.
3.  Criar um conjunto robusto de features num√©ricas e categ√≥ricas a partir de dados brutos.
4.  Diagnosticar a viabilidade de modelos preditivos (Classifica√ß√£o e Regress√£o) e interpretar seus resultados de forma cr√≠tica.

## üõ†Ô∏è Tecnologias Utilizadas
* **Banco de Dados:** SQL (SQLite)
* **An√°lise e Modelagem:** Python
* **Bibliotecas Principais:** Pandas, Scikit-learn, Seaborn, Matplotlib

## üöÄ Fases do Projeto

O projeto foi dividido em duas grandes etapas: a funda√ß√£o em SQL e a investiga√ß√£o em Python.

### Fase 1: Engenharia de Dados e An√°lise em SQL (O Cora√ß√£o do Projeto)

Esta foi a fase mais extensa e valiosa, onde transformamos o dado bruto em conhecimento.

#### 1.1. Estrutura√ß√£o e Limpeza
* Os dados foram importados para um banco SQLite.
* A feature mais desafiadora, `faixa_salarial_usd` (ex: "92860-109598"), foi processada com fun√ß√µes de string SQL (`SUBSTR`, `INSTR`) para criar tr√™s novas colunas num√©ricas: `salario_min`, `salario_max` e `salario_medio`.

#### 1.2. Engenharia de Features Avan√ßada
O foco foi criar novas colunas (features) que adicionassem intelig√™ncia e contexto ao dataset. As principais features criadas foram:

* **Features Bin√°rias (One-Hot Encoding em SQL):**
    * `tem_Python`, `tem_AWS`, `tem_SQL`, etc. Colunas que indicam com `1` ou `0` a presen√ßa de uma habilidade ou ferramenta chave, extra√≠das da coluna de texto `habilidades_necessarias`.

* **Features Relativas (Contexto de Neg√≥cio):**
    * `salario_medio_setor`: M√©dia salarial para cada setor da ind√∫stria.
    * `desvio_salarial_setor`: **(Feature de alto impacto)** Mede o qu√£o acima ou abaixo da m√©dia de seu setor uma vaga espec√≠fica est√°. Transforma um valor absoluto (sal√°rio) em um insight relativo.
    * `salario_medio_segmento`: Uma vers√£o ainda mais granular, calculando a m√©dia salarial pela combina√ß√£o de `setor` e `tamanho_empresa`.

* **Features de Demanda:**
    * `popularidade_cargo_contrato`: Mede a "popularidade" (contagem de vagas) de uma combina√ß√£o espec√≠fica de `cargo` e `tipo_contratacao`, dando uma no√ß√£o de oferta e demanda.

* **Features Temporais:**
    * `idade_vaga_dias`: Calcula h√° quantos dias a vaga foi postada, permitindo an√°lises de tempo.

#### 1.3. An√°lise de Neg√≥cio com Fun√ß√µes de Janela
* Utilizando `ROW_NUMBER() OVER (PARTITION BY ...)` em uma consulta complexa, foi poss√≠vel identificar o cargo mais requisitado para cada setor da ind√∫stria, gerando um insight estrat√©gico de alto valor.

### Fase 2: Modelagem Preditiva e Diagn√≥stico em Python

Com a base de dados robustecida, a segunda fase focou em testar hip√≥teses e diagnosticar o poder preditivo dos dados.

#### 2.1. Abordagem de Regress√£o e Diagn√≥stico de Data Leakage
* Inicialmente, um modelo de Regress√£o Linear foi treinado para prever o `salario_medio`. O resultado foi um **R¬≤ de 1.00**, um score "perfeito".
* Uma investiga√ß√£o aprofundada revelou que este resultado era devido a um **Vazamento de Dados (Data Leakage)**, causado pelas features de engenharia (`desvio_salarial_setor`, etc.) que continham a pr√≥pria resposta de forma impl√≠cita.
* **A corre√ß√£o do vazamento**, removendo as features problem√°ticas, demonstrou uma habilidade crucial em MLOps: garantir a integridade e a validade do modelo. Ap√≥s a corre√ß√£o, o R¬≤ tornou-se negativo, provando que as features restantes n√£o possu√≠am sinal linear para prever o sal√°rio.

#### 2.2. Abordagem de Classifica√ß√£o e Otimiza√ß√£o
* O projeto pivotou para um problema de classifica√ß√£o: prever o `nivel_experiencia` (J√∫nior, Pleno, S√™nior).
* Um modelo `RandomForestClassifier` foi treinado. Ap√≥s diversas rodadas de **sele√ß√£o de features** e otimiza√ß√£o com **GridSearchCV**, o modelo atingiu uma acur√°cia final de **36.62%**.

## üèÅ Conclus√£o e Principais Aprendizados

O resultado final da modelagem (acur√°cia de 36.62%) confirmou a hip√≥tese levantada na an√°lise explorat√≥ria: o dataset sint√©tico, por ser extremamente balanceado, possui um sinal preditivo muito fraco para a tarefa de classifica√ß√£o de senioridade.

**O verdadeiro sucesso deste projeto n√£o reside na performance do modelo, mas na profundidade do processo e nas habilidades demonstradas:**

> * **O principal produto entregue √© um banco de dados anal√≠tico, limpo e enriquecido com dezenas de features inteligentes, pronto para gerar insights de neg√≥cio.**

As principais compet√™ncias desenvolvidas foram:
* **SQL Avan√ßado:** Manipula√ß√£o de strings, fun√ß√µes de janela (`ROW_NUMBER`) e engenharia de features diretamente no banco de dados.
* **Diagn√≥stico de Modelos:** Identifica√ß√£o e corre√ß√£o de Data Leakage, uma habilidade essencial e avan√ßada em Machine Learning.
* **Pensamento Cr√≠tico:** An√°lise de resultados abaixo do esperado, entendendo que a limita√ß√£o n√£o estava na t√©cnica, mas na natureza intr√≠nseca dos dados.
* **Otimiza√ß√£o de Hiperpar√¢metros:** Uso de `GridSearchCV` para extrair a performance m√°xima de um modelo.

Este projeto solidifica a ideia de que a Engenharia de Dados e a cria√ß√£o de features inteligentes s√£o os pilares que sustentam qualquer iniciativa de Ci√™ncia de Dados bem-sucedida.

